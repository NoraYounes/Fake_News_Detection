{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "204d8d85",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import pandas as pd\n",
    "from sklearn.metrics import accuracy_score,confusion_matrix,classification_report\n",
    "import numpy as np\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1f5edeec",
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(37651, 48)\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "   Unnamed: 0  articlesid  fakeid  trueid  subject  label  title_count  \\\n",
       "0           0           1     1.0     NaN  US News      1           78   \n",
       "1           1           2     2.0     NaN  US News      1           69   \n",
       "2           2           3     3.0     NaN  US News      1           89   \n",
       "3           3           4     4.0     NaN  US News      1           77   \n",
       "4           4           5     5.0     NaN  US News      1           70   \n",
       "\n",
       "   text_count  article_count  title_tokenized_count  ...       NNP       WRB  \\\n",
       "0        2700           2778                      9  ...  0.419287  0.628931   \n",
       "1        1891           1960                      8  ...  0.311526  0.934579   \n",
       "2        3381           3470                     10  ...  0.341297  0.511945   \n",
       "3        2599           2676                      8  ...  0.439560  0.439560   \n",
       "4        2346           2416                      7  ...  0.000000  0.230947   \n",
       "\n",
       "        WDT       PDT        EX  RBS  NNPS   UH  WP$  POS  \n",
       "0  0.209644  0.209644  0.000000  0.0   0.0  0.0  0.0  0.0  \n",
       "1  0.000000  0.000000  0.000000  0.0   0.0  0.0  0.0  0.0  \n",
       "2  0.511945  0.000000  0.170648  0.0   0.0  0.0  0.0  0.0  \n",
       "3  0.879121  0.000000  0.000000  0.0   0.0  0.0  0.0  0.0  \n",
       "4  0.461894  0.230947  0.461894  0.0   0.0  0.0  0.0  0.0  \n",
       "\n",
       "[5 rows x 48 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Unnamed: 0</th>\n      <th>articlesid</th>\n      <th>fakeid</th>\n      <th>trueid</th>\n      <th>subject</th>\n      <th>label</th>\n      <th>title_count</th>\n      <th>text_count</th>\n      <th>article_count</th>\n      <th>title_tokenized_count</th>\n      <th>...</th>\n      <th>NNP</th>\n      <th>WRB</th>\n      <th>WDT</th>\n      <th>PDT</th>\n      <th>EX</th>\n      <th>RBS</th>\n      <th>NNPS</th>\n      <th>UH</th>\n      <th>WP$</th>\n      <th>POS</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>1</td>\n      <td>1.0</td>\n      <td>NaN</td>\n      <td>US News</td>\n      <td>1</td>\n      <td>78</td>\n      <td>2700</td>\n      <td>2778</td>\n      <td>9</td>\n      <td>...</td>\n      <td>0.419287</td>\n      <td>0.628931</td>\n      <td>0.209644</td>\n      <td>0.209644</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>2</td>\n      <td>2.0</td>\n      <td>NaN</td>\n      <td>US News</td>\n      <td>1</td>\n      <td>69</td>\n      <td>1891</td>\n      <td>1960</td>\n      <td>8</td>\n      <td>...</td>\n      <td>0.311526</td>\n      <td>0.934579</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td>3</td>\n      <td>3.0</td>\n      <td>NaN</td>\n      <td>US News</td>\n      <td>1</td>\n      <td>89</td>\n      <td>3381</td>\n      <td>3470</td>\n      <td>10</td>\n      <td>...</td>\n      <td>0.341297</td>\n      <td>0.511945</td>\n      <td>0.511945</td>\n      <td>0.000000</td>\n      <td>0.170648</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3</td>\n      <td>4</td>\n      <td>4.0</td>\n      <td>NaN</td>\n      <td>US News</td>\n      <td>1</td>\n      <td>77</td>\n      <td>2599</td>\n      <td>2676</td>\n      <td>8</td>\n      <td>...</td>\n      <td>0.439560</td>\n      <td>0.439560</td>\n      <td>0.879121</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4</td>\n      <td>5</td>\n      <td>5.0</td>\n      <td>NaN</td>\n      <td>US News</td>\n      <td>1</td>\n      <td>70</td>\n      <td>2346</td>\n      <td>2416</td>\n      <td>7</td>\n      <td>...</td>\n      <td>0.000000</td>\n      <td>0.230947</td>\n      <td>0.461894</td>\n      <td>0.230947</td>\n      <td>0.461894</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 48 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 16
    }
   ],
   "source": [
    "# Read CSV file\n",
    "df = pd.read_csv('NLP_df_finalnum(J29).csv')\n",
    "\n",
    "# Check df\n",
    "print(df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5a295799",
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "Index(['label', 'title_count', 'text_count', 'title_tokenized_count',\n",
       "       'text_tokenized_count', 'US News', 'World News', 'JJ', 'NN', 'VBZ',\n",
       "       'RP', 'VBG', 'VBP', 'DT', 'RB', 'VB', 'CC', 'PRP', 'IN', 'VBD', 'TO',\n",
       "       'PRP$', 'NNS', 'JJS', 'CD', 'JJR', 'RBR', 'VBN', 'MD', 'WP', 'FW',\n",
       "       'NNP', 'WRB', 'WDT', 'PDT', 'EX', 'RBS', 'NNPS', 'UH', 'WP$', 'POS'],\n",
       "      dtype='object')"
      ]
     },
     "metadata": {},
     "execution_count": 17
    }
   ],
   "source": [
    "# Drop columns that will not be used as features\n",
    "df = df.drop(columns=['Unnamed: 0','articlesid','fakeid','trueid','subject','article_count','article_tokenized_count'])\n",
    "\n",
    "# Check df columns\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "490bb45c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "label                      int64\n",
       "title_count                int64\n",
       "text_count                 int64\n",
       "title_tokenized_count      int64\n",
       "text_tokenized_count       int64\n",
       "US News                    int64\n",
       "World News                 int64\n",
       "JJ                       float64\n",
       "NN                       float64\n",
       "VBZ                      float64\n",
       "RP                       float64\n",
       "VBG                      float64\n",
       "VBP                      float64\n",
       "DT                       float64\n",
       "RB                       float64\n",
       "VB                       float64\n",
       "CC                       float64\n",
       "PRP                      float64\n",
       "IN                       float64\n",
       "VBD                      float64\n",
       "TO                       float64\n",
       "PRP$                     float64\n",
       "NNS                      float64\n",
       "JJS                      float64\n",
       "CD                       float64\n",
       "JJR                      float64\n",
       "RBR                      float64\n",
       "VBN                      float64\n",
       "MD                       float64\n",
       "WP                       float64\n",
       "FW                       float64\n",
       "NNP                      float64\n",
       "WRB                      float64\n",
       "WDT                      float64\n",
       "PDT                      float64\n",
       "EX                       float64\n",
       "RBS                      float64\n",
       "NNPS                     float64\n",
       "UH                       float64\n",
       "WP$                      float64\n",
       "POS                      float64\n",
       "dtype: object"
      ]
     },
     "metadata": {},
     "execution_count": 18
    }
   ],
   "source": [
    "# Show df columns and data types \n",
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "519bb855",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "       title_count  text_count  title_tokenized_count  text_tokenized_count  \\\n",
       "0         0.151024    0.150975              -0.009189              0.150104   \n",
       "1        -0.283590   -0.271992              -0.424534             -0.261377   \n",
       "2         0.682218    0.507019               0.406155              0.517693   \n",
       "3         0.102733    0.098169              -0.424534              0.166563   \n",
       "4        -0.235300   -0.034106              -0.839878             -0.102271   \n",
       "...            ...         ...                    ...                   ...   \n",
       "37646    -0.718204    0.197506              -0.424534              0.172049   \n",
       "37647    -1.104527   -0.844486              -1.255223             -0.853909   \n",
       "37648    -1.249399   -0.248465              -1.670568             -0.310755   \n",
       "37649    -0.669913   -0.636924              -0.839878             -0.623480   \n",
       "37650    -1.249399   -0.570525              -1.255223             -0.519238   \n",
       "\n",
       "        US News  World News        JJ        NN       VBZ        RP  ...  \\\n",
       "0      0.629476   -0.629476  0.623820 -0.669135  0.427033  0.038871  ...   \n",
       "1      0.629476   -0.629476  0.170066  1.317906  0.054895 -0.184545  ...   \n",
       "2      0.629476   -0.629476 -0.193333  0.524035 -0.340731  0.230976  ...   \n",
       "3      0.629476   -0.629476 -1.466540  1.695557  1.725102  1.447888  ...   \n",
       "4      0.629476   -0.629476 -1.349540 -1.242219 -0.591402  0.606019  ...   \n",
       "...         ...         ...       ...       ...       ...       ...  ...   \n",
       "37646 -1.588624    1.588624 -0.187486 -0.680458 -0.674837  0.956873  ...   \n",
       "37647 -1.588624    1.588624  0.121581  1.042047 -1.320284 -0.830421  ...   \n",
       "37648 -1.588624    1.588624 -0.244461 -0.115542  2.075204  1.065855  ...   \n",
       "37649 -1.588624    1.588624  0.853923  0.168636 -1.199539 -0.830421  ...   \n",
       "37650 -1.588624    1.588624 -0.531272  0.944945  0.072773  0.147533  ...   \n",
       "\n",
       "            NNP       WRB       WDT       PDT        EX       RBS      NNPS  \\\n",
       "0      1.332610  0.515030 -0.656953  0.953495 -0.490145 -0.345675 -0.213503   \n",
       "1      0.916963  1.146512 -1.100969 -0.374586 -0.490145 -0.345675 -0.213503   \n",
       "2      1.031791  0.273333 -0.016689 -0.374586  0.194702 -0.345675 -0.213503   \n",
       "3      1.410806  0.123783  0.760974 -0.374586 -0.490145 -0.345675 -0.213503   \n",
       "4     -0.284635 -0.307221 -0.122697  1.088451  1.363530 -0.345675 -0.213503   \n",
       "...         ...       ...       ...       ...       ...       ...       ...   \n",
       "37646 -0.284635 -0.784366  0.724859 -0.374586 -0.490145 -0.345675 -0.213503   \n",
       "37647 -0.284635 -0.784366 -1.100969 -0.374586 -0.490145 -0.345675 -0.213503   \n",
       "37648  0.891319 -0.154476 -1.100969 -0.374586  0.733393  1.592095 -0.213503   \n",
       "37649 -0.284635  0.194799 -1.100969  2.627759  3.313843 -0.345675 -0.213503   \n",
       "37650 -0.284635 -0.784366  0.897107 -0.374586 -0.490145 -0.345675 -0.213503   \n",
       "\n",
       "             UH       WP$       POS  \n",
       "0     -0.054992 -0.208162 -0.036476  \n",
       "1     -0.054992 -0.208162 -0.036476  \n",
       "2     -0.054992 -0.208162 -0.036476  \n",
       "3     -0.054992 -0.208162 -0.036476  \n",
       "4     -0.054992 -0.208162 -0.036476  \n",
       "...         ...       ...       ...  \n",
       "37646 -0.054992 -0.208162 -0.036476  \n",
       "37647 -0.054992 -0.208162 -0.036476  \n",
       "37648 -0.054992 -0.208162 -0.036476  \n",
       "37649 -0.054992 -0.208162 -0.036476  \n",
       "37650 -0.054992 -0.208162 -0.036476  \n",
       "\n",
       "[37651 rows x 40 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>title_count</th>\n      <th>text_count</th>\n      <th>title_tokenized_count</th>\n      <th>text_tokenized_count</th>\n      <th>US News</th>\n      <th>World News</th>\n      <th>JJ</th>\n      <th>NN</th>\n      <th>VBZ</th>\n      <th>RP</th>\n      <th>...</th>\n      <th>NNP</th>\n      <th>WRB</th>\n      <th>WDT</th>\n      <th>PDT</th>\n      <th>EX</th>\n      <th>RBS</th>\n      <th>NNPS</th>\n      <th>UH</th>\n      <th>WP$</th>\n      <th>POS</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.151024</td>\n      <td>0.150975</td>\n      <td>-0.009189</td>\n      <td>0.150104</td>\n      <td>0.629476</td>\n      <td>-0.629476</td>\n      <td>0.623820</td>\n      <td>-0.669135</td>\n      <td>0.427033</td>\n      <td>0.038871</td>\n      <td>...</td>\n      <td>1.332610</td>\n      <td>0.515030</td>\n      <td>-0.656953</td>\n      <td>0.953495</td>\n      <td>-0.490145</td>\n      <td>-0.345675</td>\n      <td>-0.213503</td>\n      <td>-0.054992</td>\n      <td>-0.208162</td>\n      <td>-0.036476</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>-0.283590</td>\n      <td>-0.271992</td>\n      <td>-0.424534</td>\n      <td>-0.261377</td>\n      <td>0.629476</td>\n      <td>-0.629476</td>\n      <td>0.170066</td>\n      <td>1.317906</td>\n      <td>0.054895</td>\n      <td>-0.184545</td>\n      <td>...</td>\n      <td>0.916963</td>\n      <td>1.146512</td>\n      <td>-1.100969</td>\n      <td>-0.374586</td>\n      <td>-0.490145</td>\n      <td>-0.345675</td>\n      <td>-0.213503</td>\n      <td>-0.054992</td>\n      <td>-0.208162</td>\n      <td>-0.036476</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.682218</td>\n      <td>0.507019</td>\n      <td>0.406155</td>\n      <td>0.517693</td>\n      <td>0.629476</td>\n      <td>-0.629476</td>\n      <td>-0.193333</td>\n      <td>0.524035</td>\n      <td>-0.340731</td>\n      <td>0.230976</td>\n      <td>...</td>\n      <td>1.031791</td>\n      <td>0.273333</td>\n      <td>-0.016689</td>\n      <td>-0.374586</td>\n      <td>0.194702</td>\n      <td>-0.345675</td>\n      <td>-0.213503</td>\n      <td>-0.054992</td>\n      <td>-0.208162</td>\n      <td>-0.036476</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.102733</td>\n      <td>0.098169</td>\n      <td>-0.424534</td>\n      <td>0.166563</td>\n      <td>0.629476</td>\n      <td>-0.629476</td>\n      <td>-1.466540</td>\n      <td>1.695557</td>\n      <td>1.725102</td>\n      <td>1.447888</td>\n      <td>...</td>\n      <td>1.410806</td>\n      <td>0.123783</td>\n      <td>0.760974</td>\n      <td>-0.374586</td>\n      <td>-0.490145</td>\n      <td>-0.345675</td>\n      <td>-0.213503</td>\n      <td>-0.054992</td>\n      <td>-0.208162</td>\n      <td>-0.036476</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>-0.235300</td>\n      <td>-0.034106</td>\n      <td>-0.839878</td>\n      <td>-0.102271</td>\n      <td>0.629476</td>\n      <td>-0.629476</td>\n      <td>-1.349540</td>\n      <td>-1.242219</td>\n      <td>-0.591402</td>\n      <td>0.606019</td>\n      <td>...</td>\n      <td>-0.284635</td>\n      <td>-0.307221</td>\n      <td>-0.122697</td>\n      <td>1.088451</td>\n      <td>1.363530</td>\n      <td>-0.345675</td>\n      <td>-0.213503</td>\n      <td>-0.054992</td>\n      <td>-0.208162</td>\n      <td>-0.036476</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>37646</th>\n      <td>-0.718204</td>\n      <td>0.197506</td>\n      <td>-0.424534</td>\n      <td>0.172049</td>\n      <td>-1.588624</td>\n      <td>1.588624</td>\n      <td>-0.187486</td>\n      <td>-0.680458</td>\n      <td>-0.674837</td>\n      <td>0.956873</td>\n      <td>...</td>\n      <td>-0.284635</td>\n      <td>-0.784366</td>\n      <td>0.724859</td>\n      <td>-0.374586</td>\n      <td>-0.490145</td>\n      <td>-0.345675</td>\n      <td>-0.213503</td>\n      <td>-0.054992</td>\n      <td>-0.208162</td>\n      <td>-0.036476</td>\n    </tr>\n    <tr>\n      <th>37647</th>\n      <td>-1.104527</td>\n      <td>-0.844486</td>\n      <td>-1.255223</td>\n      <td>-0.853909</td>\n      <td>-1.588624</td>\n      <td>1.588624</td>\n      <td>0.121581</td>\n      <td>1.042047</td>\n      <td>-1.320284</td>\n      <td>-0.830421</td>\n      <td>...</td>\n      <td>-0.284635</td>\n      <td>-0.784366</td>\n      <td>-1.100969</td>\n      <td>-0.374586</td>\n      <td>-0.490145</td>\n      <td>-0.345675</td>\n      <td>-0.213503</td>\n      <td>-0.054992</td>\n      <td>-0.208162</td>\n      <td>-0.036476</td>\n    </tr>\n    <tr>\n      <th>37648</th>\n      <td>-1.249399</td>\n      <td>-0.248465</td>\n      <td>-1.670568</td>\n      <td>-0.310755</td>\n      <td>-1.588624</td>\n      <td>1.588624</td>\n      <td>-0.244461</td>\n      <td>-0.115542</td>\n      <td>2.075204</td>\n      <td>1.065855</td>\n      <td>...</td>\n      <td>0.891319</td>\n      <td>-0.154476</td>\n      <td>-1.100969</td>\n      <td>-0.374586</td>\n      <td>0.733393</td>\n      <td>1.592095</td>\n      <td>-0.213503</td>\n      <td>-0.054992</td>\n      <td>-0.208162</td>\n      <td>-0.036476</td>\n    </tr>\n    <tr>\n      <th>37649</th>\n      <td>-0.669913</td>\n      <td>-0.636924</td>\n      <td>-0.839878</td>\n      <td>-0.623480</td>\n      <td>-1.588624</td>\n      <td>1.588624</td>\n      <td>0.853923</td>\n      <td>0.168636</td>\n      <td>-1.199539</td>\n      <td>-0.830421</td>\n      <td>...</td>\n      <td>-0.284635</td>\n      <td>0.194799</td>\n      <td>-1.100969</td>\n      <td>2.627759</td>\n      <td>3.313843</td>\n      <td>-0.345675</td>\n      <td>-0.213503</td>\n      <td>-0.054992</td>\n      <td>-0.208162</td>\n      <td>-0.036476</td>\n    </tr>\n    <tr>\n      <th>37650</th>\n      <td>-1.249399</td>\n      <td>-0.570525</td>\n      <td>-1.255223</td>\n      <td>-0.519238</td>\n      <td>-1.588624</td>\n      <td>1.588624</td>\n      <td>-0.531272</td>\n      <td>0.944945</td>\n      <td>0.072773</td>\n      <td>0.147533</td>\n      <td>...</td>\n      <td>-0.284635</td>\n      <td>-0.784366</td>\n      <td>0.897107</td>\n      <td>-0.374586</td>\n      <td>-0.490145</td>\n      <td>-0.345675</td>\n      <td>-0.213503</td>\n      <td>-0.054992</td>\n      <td>-0.208162</td>\n      <td>-0.036476</td>\n    </tr>\n  </tbody>\n</table>\n<p>37651 rows × 40 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 19
    }
   ],
   "source": [
    "# Scale data\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Initiate StandardScaler\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Create dataframe without label column\n",
    "df_nolabel = df.drop(columns= ['label'])\n",
    "\n",
    "# Fit\n",
    "scaler.fit(df_nolabel)\n",
    "\n",
    "# Save the scaler\n",
    "pickle.dump(scaler, open('scaler.sav', 'wb'))\n",
    "\n",
    "# Transform\n",
    "df_scaled = pd.DataFrame(scaler.transform(df_nolabel),columns=df_nolabel.columns)\n",
    "\n",
    "df_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e2f50abb",
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "       label  title_count  text_count  title_tokenized_count  \\\n",
       "0          1     0.151024    0.150975              -0.009189   \n",
       "1          1    -0.283590   -0.271992              -0.424534   \n",
       "2          1     0.682218    0.507019               0.406155   \n",
       "3          1     0.102733    0.098169              -0.424534   \n",
       "4          1    -0.235300   -0.034106              -0.839878   \n",
       "...      ...          ...         ...                    ...   \n",
       "37646      0    -0.718204    0.197506              -0.424534   \n",
       "37647      0    -1.104527   -0.844486              -1.255223   \n",
       "37648      0    -1.249399   -0.248465              -1.670568   \n",
       "37649      0    -0.669913   -0.636924              -0.839878   \n",
       "37650      0    -1.249399   -0.570525              -1.255223   \n",
       "\n",
       "       text_tokenized_count   US News  World News        JJ        NN  \\\n",
       "0                  0.150104  0.629476   -0.629476  0.623820 -0.669135   \n",
       "1                 -0.261377  0.629476   -0.629476  0.170066  1.317906   \n",
       "2                  0.517693  0.629476   -0.629476 -0.193333  0.524035   \n",
       "3                  0.166563  0.629476   -0.629476 -1.466540  1.695557   \n",
       "4                 -0.102271  0.629476   -0.629476 -1.349540 -1.242219   \n",
       "...                     ...       ...         ...       ...       ...   \n",
       "37646              0.172049 -1.588624    1.588624 -0.187486 -0.680458   \n",
       "37647             -0.853909 -1.588624    1.588624  0.121581  1.042047   \n",
       "37648             -0.310755 -1.588624    1.588624 -0.244461 -0.115542   \n",
       "37649             -0.623480 -1.588624    1.588624  0.853923  0.168636   \n",
       "37650             -0.519238 -1.588624    1.588624 -0.531272  0.944945   \n",
       "\n",
       "            VBZ  ...       NNP       WRB       WDT       PDT        EX  \\\n",
       "0      0.427033  ...  1.332610  0.515030 -0.656953  0.953495 -0.490145   \n",
       "1      0.054895  ...  0.916963  1.146512 -1.100969 -0.374586 -0.490145   \n",
       "2     -0.340731  ...  1.031791  0.273333 -0.016689 -0.374586  0.194702   \n",
       "3      1.725102  ...  1.410806  0.123783  0.760974 -0.374586 -0.490145   \n",
       "4     -0.591402  ... -0.284635 -0.307221 -0.122697  1.088451  1.363530   \n",
       "...         ...  ...       ...       ...       ...       ...       ...   \n",
       "37646 -0.674837  ... -0.284635 -0.784366  0.724859 -0.374586 -0.490145   \n",
       "37647 -1.320284  ... -0.284635 -0.784366 -1.100969 -0.374586 -0.490145   \n",
       "37648  2.075204  ...  0.891319 -0.154476 -1.100969 -0.374586  0.733393   \n",
       "37649 -1.199539  ... -0.284635  0.194799 -1.100969  2.627759  3.313843   \n",
       "37650  0.072773  ... -0.284635 -0.784366  0.897107 -0.374586 -0.490145   \n",
       "\n",
       "            RBS      NNPS        UH       WP$       POS  \n",
       "0     -0.345675 -0.213503 -0.054992 -0.208162 -0.036476  \n",
       "1     -0.345675 -0.213503 -0.054992 -0.208162 -0.036476  \n",
       "2     -0.345675 -0.213503 -0.054992 -0.208162 -0.036476  \n",
       "3     -0.345675 -0.213503 -0.054992 -0.208162 -0.036476  \n",
       "4     -0.345675 -0.213503 -0.054992 -0.208162 -0.036476  \n",
       "...         ...       ...       ...       ...       ...  \n",
       "37646 -0.345675 -0.213503 -0.054992 -0.208162 -0.036476  \n",
       "37647 -0.345675 -0.213503 -0.054992 -0.208162 -0.036476  \n",
       "37648  1.592095 -0.213503 -0.054992 -0.208162 -0.036476  \n",
       "37649 -0.345675 -0.213503 -0.054992 -0.208162 -0.036476  \n",
       "37650 -0.345675 -0.213503 -0.054992 -0.208162 -0.036476  \n",
       "\n",
       "[37651 rows x 41 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>label</th>\n      <th>title_count</th>\n      <th>text_count</th>\n      <th>title_tokenized_count</th>\n      <th>text_tokenized_count</th>\n      <th>US News</th>\n      <th>World News</th>\n      <th>JJ</th>\n      <th>NN</th>\n      <th>VBZ</th>\n      <th>...</th>\n      <th>NNP</th>\n      <th>WRB</th>\n      <th>WDT</th>\n      <th>PDT</th>\n      <th>EX</th>\n      <th>RBS</th>\n      <th>NNPS</th>\n      <th>UH</th>\n      <th>WP$</th>\n      <th>POS</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>0.151024</td>\n      <td>0.150975</td>\n      <td>-0.009189</td>\n      <td>0.150104</td>\n      <td>0.629476</td>\n      <td>-0.629476</td>\n      <td>0.623820</td>\n      <td>-0.669135</td>\n      <td>0.427033</td>\n      <td>...</td>\n      <td>1.332610</td>\n      <td>0.515030</td>\n      <td>-0.656953</td>\n      <td>0.953495</td>\n      <td>-0.490145</td>\n      <td>-0.345675</td>\n      <td>-0.213503</td>\n      <td>-0.054992</td>\n      <td>-0.208162</td>\n      <td>-0.036476</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>-0.283590</td>\n      <td>-0.271992</td>\n      <td>-0.424534</td>\n      <td>-0.261377</td>\n      <td>0.629476</td>\n      <td>-0.629476</td>\n      <td>0.170066</td>\n      <td>1.317906</td>\n      <td>0.054895</td>\n      <td>...</td>\n      <td>0.916963</td>\n      <td>1.146512</td>\n      <td>-1.100969</td>\n      <td>-0.374586</td>\n      <td>-0.490145</td>\n      <td>-0.345675</td>\n      <td>-0.213503</td>\n      <td>-0.054992</td>\n      <td>-0.208162</td>\n      <td>-0.036476</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1</td>\n      <td>0.682218</td>\n      <td>0.507019</td>\n      <td>0.406155</td>\n      <td>0.517693</td>\n      <td>0.629476</td>\n      <td>-0.629476</td>\n      <td>-0.193333</td>\n      <td>0.524035</td>\n      <td>-0.340731</td>\n      <td>...</td>\n      <td>1.031791</td>\n      <td>0.273333</td>\n      <td>-0.016689</td>\n      <td>-0.374586</td>\n      <td>0.194702</td>\n      <td>-0.345675</td>\n      <td>-0.213503</td>\n      <td>-0.054992</td>\n      <td>-0.208162</td>\n      <td>-0.036476</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1</td>\n      <td>0.102733</td>\n      <td>0.098169</td>\n      <td>-0.424534</td>\n      <td>0.166563</td>\n      <td>0.629476</td>\n      <td>-0.629476</td>\n      <td>-1.466540</td>\n      <td>1.695557</td>\n      <td>1.725102</td>\n      <td>...</td>\n      <td>1.410806</td>\n      <td>0.123783</td>\n      <td>0.760974</td>\n      <td>-0.374586</td>\n      <td>-0.490145</td>\n      <td>-0.345675</td>\n      <td>-0.213503</td>\n      <td>-0.054992</td>\n      <td>-0.208162</td>\n      <td>-0.036476</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1</td>\n      <td>-0.235300</td>\n      <td>-0.034106</td>\n      <td>-0.839878</td>\n      <td>-0.102271</td>\n      <td>0.629476</td>\n      <td>-0.629476</td>\n      <td>-1.349540</td>\n      <td>-1.242219</td>\n      <td>-0.591402</td>\n      <td>...</td>\n      <td>-0.284635</td>\n      <td>-0.307221</td>\n      <td>-0.122697</td>\n      <td>1.088451</td>\n      <td>1.363530</td>\n      <td>-0.345675</td>\n      <td>-0.213503</td>\n      <td>-0.054992</td>\n      <td>-0.208162</td>\n      <td>-0.036476</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>37646</th>\n      <td>0</td>\n      <td>-0.718204</td>\n      <td>0.197506</td>\n      <td>-0.424534</td>\n      <td>0.172049</td>\n      <td>-1.588624</td>\n      <td>1.588624</td>\n      <td>-0.187486</td>\n      <td>-0.680458</td>\n      <td>-0.674837</td>\n      <td>...</td>\n      <td>-0.284635</td>\n      <td>-0.784366</td>\n      <td>0.724859</td>\n      <td>-0.374586</td>\n      <td>-0.490145</td>\n      <td>-0.345675</td>\n      <td>-0.213503</td>\n      <td>-0.054992</td>\n      <td>-0.208162</td>\n      <td>-0.036476</td>\n    </tr>\n    <tr>\n      <th>37647</th>\n      <td>0</td>\n      <td>-1.104527</td>\n      <td>-0.844486</td>\n      <td>-1.255223</td>\n      <td>-0.853909</td>\n      <td>-1.588624</td>\n      <td>1.588624</td>\n      <td>0.121581</td>\n      <td>1.042047</td>\n      <td>-1.320284</td>\n      <td>...</td>\n      <td>-0.284635</td>\n      <td>-0.784366</td>\n      <td>-1.100969</td>\n      <td>-0.374586</td>\n      <td>-0.490145</td>\n      <td>-0.345675</td>\n      <td>-0.213503</td>\n      <td>-0.054992</td>\n      <td>-0.208162</td>\n      <td>-0.036476</td>\n    </tr>\n    <tr>\n      <th>37648</th>\n      <td>0</td>\n      <td>-1.249399</td>\n      <td>-0.248465</td>\n      <td>-1.670568</td>\n      <td>-0.310755</td>\n      <td>-1.588624</td>\n      <td>1.588624</td>\n      <td>-0.244461</td>\n      <td>-0.115542</td>\n      <td>2.075204</td>\n      <td>...</td>\n      <td>0.891319</td>\n      <td>-0.154476</td>\n      <td>-1.100969</td>\n      <td>-0.374586</td>\n      <td>0.733393</td>\n      <td>1.592095</td>\n      <td>-0.213503</td>\n      <td>-0.054992</td>\n      <td>-0.208162</td>\n      <td>-0.036476</td>\n    </tr>\n    <tr>\n      <th>37649</th>\n      <td>0</td>\n      <td>-0.669913</td>\n      <td>-0.636924</td>\n      <td>-0.839878</td>\n      <td>-0.623480</td>\n      <td>-1.588624</td>\n      <td>1.588624</td>\n      <td>0.853923</td>\n      <td>0.168636</td>\n      <td>-1.199539</td>\n      <td>...</td>\n      <td>-0.284635</td>\n      <td>0.194799</td>\n      <td>-1.100969</td>\n      <td>2.627759</td>\n      <td>3.313843</td>\n      <td>-0.345675</td>\n      <td>-0.213503</td>\n      <td>-0.054992</td>\n      <td>-0.208162</td>\n      <td>-0.036476</td>\n    </tr>\n    <tr>\n      <th>37650</th>\n      <td>0</td>\n      <td>-1.249399</td>\n      <td>-0.570525</td>\n      <td>-1.255223</td>\n      <td>-0.519238</td>\n      <td>-1.588624</td>\n      <td>1.588624</td>\n      <td>-0.531272</td>\n      <td>0.944945</td>\n      <td>0.072773</td>\n      <td>...</td>\n      <td>-0.284635</td>\n      <td>-0.784366</td>\n      <td>0.897107</td>\n      <td>-0.374586</td>\n      <td>-0.490145</td>\n      <td>-0.345675</td>\n      <td>-0.213503</td>\n      <td>-0.054992</td>\n      <td>-0.208162</td>\n      <td>-0.036476</td>\n    </tr>\n  </tbody>\n</table>\n<p>37651 rows × 41 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 20
    }
   ],
   "source": [
    "# Add scaled values to dataframe\n",
    "df.update(df_scaled) \n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "20a0d5a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assign variables (features and target y and X)\n",
    "y = df.label\n",
    "X = df.drop(columns=['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3f9a0c3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import train_test_split module\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split data into training and testing sets \n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=78, test_size=0.20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "62dbbbfe",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# # MODEL 1: Naive Bayes/GaussianNB()\n",
    "\n",
    "# #Import GaussianNB library\n",
    "# from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "# # Initiate model\n",
    "# nb_model = GaussianNB()\n",
    "\n",
    "# # Train model\n",
    "# nb_model.fit(X_train, y_train)\n",
    "\n",
    "# # Create model predictions\n",
    "# y_pred = nb_model.predict(X_test)\n",
    "\n",
    "# # Validate Model(1): Accuracy Score \n",
    "# accuracy = accuracy_score(y_test, y_pred)*100\n",
    "# print(accuracy)\n",
    "\n",
    "# # Validate Model(2): Confusion Matrix\n",
    "# print(confusion_matrix(y_test, y_pred))\n",
    "\n",
    "# # Validate Model(3): Classification Report\n",
    "# print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "750ed93c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# # CODE FROM: https://inblog.in/Feature-Importance-in-Naive-Bayes-Classifiers-5qob5d5sFW\n",
    "\n",
    "# # Calculate feature importance in the Naive Bayes/GaussianNB() model.\n",
    "# from sklearn.inspection import permutation_importance\n",
    "\n",
    "# imps = permutation_importance(nb_model, X_test, y_test)\n",
    "# importances = imps.importances_mean\n",
    "# std = imps.importances_std\n",
    "# indices = np.argsort(importances)[::-1]\n",
    "\n",
    "# features = X.columns\n",
    "\n",
    "# # Print the feature ranking\n",
    "# print(\"Feature ranking:\")\n",
    "# for f in range(X_test.shape[1]):\n",
    "#     print(\"%d. %s (%f)\" % (f + 1, features[indices[f]], importances[indices[f]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "af1b4fc6",
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "92.94914354003453\n[[4042  172]\n [ 359 2958]]\n              precision    recall  f1-score   support\n\n           0       0.92      0.96      0.94      4214\n           1       0.95      0.89      0.92      3317\n\n    accuracy                           0.93      7531\n   macro avg       0.93      0.93      0.93      7531\nweighted avg       0.93      0.93      0.93      7531\n\n"
     ]
    }
   ],
   "source": [
    "# MODEL 2: SVM\n",
    "\n",
    "#Import library \n",
    "from sklearn.svm import SVC\n",
    "\n",
    "# Initiate model\n",
    "svm_model = SVC(kernel='linear')\n",
    "\n",
    "# Train model\n",
    "svm_model.fit(X_train, y_train)\n",
    "\n",
    "# Create model predictions\n",
    "y_pred = svm_model.predict(X_test)\n",
    "\n",
    "# Validate Model(1): Accuracy Score \n",
    "accuracy = accuracy_score(y_test, y_pred)*100\n",
    "print(accuracy)\n",
    "\n",
    "# Validate Model(2): Confusion Matrix\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "\n",
    "# Validate Model(3): Classification Report\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "671db8f5",
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Feature ranking:\n1. text_tokenized_count (0.169831)\n2. title_count (0.152782)\n3. text_count (0.148347)\n4. VBD (0.051786)\n5. NNS (0.021431)\n6. MD (0.019280)\n7. RB (0.013119)\n8. PRP (0.011791)\n9. TO (0.010145)\n10. JJ (0.007648)\n11. US News (0.006374)\n12. World News (0.006374)\n13. IN (0.005604)\n14. WRB (0.005019)\n15. RP (0.004541)\n16. WP (0.002576)\n17. VBN (0.001992)\n18. NN (0.001912)\n19. VB (0.001779)\n20. VBZ (0.001408)\n21. title_tokenized_count (0.001381)\n22. DT (0.001248)\n23. VBP (0.000505)\n24. RBS (0.000398)\n25. WP$ (0.000372)\n26. PDT (0.000319)\n27. CC (0.000266)\n28. NNP (0.000239)\n29. UH (0.000186)\n30. EX (0.000106)\n31. FW (0.000027)\n32. WDT (0.000000)\n33. POS (0.000000)\n34. VBG (-0.000027)\n35. PRP$ (-0.000027)\n36. JJS (-0.000186)\n37. RBR (-0.000186)\n38. CD (-0.000345)\n39. NNPS (-0.000505)\n40. JJR (-0.000611)\n"
     ]
    }
   ],
   "source": [
    "# Import permutation_importance library\n",
    "from sklearn.inspection import permutation_importance\n",
    "\n",
    "# Calculate feature importance SVM model.\n",
    "svm_imps = permutation_importance(svm_model, X_test, y_test)\n",
    "svm_importances = svm_imps.importances_mean\n",
    "std = svm_imps.importances_std\n",
    "indices = np.argsort(svm_importances)[::-1]\n",
    "\n",
    "svm_features = X.columns\n",
    "\n",
    "# Print the feature ranking\n",
    "print(\"Feature ranking:\")\n",
    "for f in range(X_test.shape[1]):\n",
    "    print(\"%d. %s (%f)\" % (f + 1, svm_features[indices[f]], svm_importances[indices[f]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "4a7d37f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save model to disk\n",
    "pickle.dump(svm_model, open('svm_model.sav', 'wb'))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python385jvsc74a57bd04e16bc90bb1be4fcd3e766e2f5d73f05719f516a7206bf1e9e77281fd34acfc0",
   "display_name": "Python 3.8.5 64-bit ('PythonData': conda)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}