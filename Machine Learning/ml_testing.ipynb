{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "204d8d85",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import pandas as pd\n",
    "from sklearn.metrics import accuracy_score,confusion_matrix,classification_report\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1f5edeec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(37651, 48)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>articlesid</th>\n",
       "      <th>fakeid</th>\n",
       "      <th>trueid</th>\n",
       "      <th>subject</th>\n",
       "      <th>label</th>\n",
       "      <th>title_count</th>\n",
       "      <th>text_count</th>\n",
       "      <th>article_count</th>\n",
       "      <th>title_tokenized_count</th>\n",
       "      <th>...</th>\n",
       "      <th>NNP</th>\n",
       "      <th>WRB</th>\n",
       "      <th>WDT</th>\n",
       "      <th>PDT</th>\n",
       "      <th>EX</th>\n",
       "      <th>RBS</th>\n",
       "      <th>NNPS</th>\n",
       "      <th>UH</th>\n",
       "      <th>WP$</th>\n",
       "      <th>POS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>US News</td>\n",
       "      <td>1</td>\n",
       "      <td>78</td>\n",
       "      <td>2700</td>\n",
       "      <td>2778</td>\n",
       "      <td>9</td>\n",
       "      <td>...</td>\n",
       "      <td>0.419287</td>\n",
       "      <td>0.628931</td>\n",
       "      <td>0.209644</td>\n",
       "      <td>0.209644</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>US News</td>\n",
       "      <td>1</td>\n",
       "      <td>69</td>\n",
       "      <td>1891</td>\n",
       "      <td>1960</td>\n",
       "      <td>8</td>\n",
       "      <td>...</td>\n",
       "      <td>0.311526</td>\n",
       "      <td>0.934579</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>US News</td>\n",
       "      <td>1</td>\n",
       "      <td>89</td>\n",
       "      <td>3381</td>\n",
       "      <td>3470</td>\n",
       "      <td>10</td>\n",
       "      <td>...</td>\n",
       "      <td>0.341297</td>\n",
       "      <td>0.511945</td>\n",
       "      <td>0.511945</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.170648</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>US News</td>\n",
       "      <td>1</td>\n",
       "      <td>77</td>\n",
       "      <td>2599</td>\n",
       "      <td>2676</td>\n",
       "      <td>8</td>\n",
       "      <td>...</td>\n",
       "      <td>0.439560</td>\n",
       "      <td>0.439560</td>\n",
       "      <td>0.879121</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>US News</td>\n",
       "      <td>1</td>\n",
       "      <td>70</td>\n",
       "      <td>2346</td>\n",
       "      <td>2416</td>\n",
       "      <td>7</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.230947</td>\n",
       "      <td>0.461894</td>\n",
       "      <td>0.230947</td>\n",
       "      <td>0.461894</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 48 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  articlesid  fakeid  trueid  subject  label  title_count  \\\n",
       "0           0           1     1.0     NaN  US News      1           78   \n",
       "1           1           2     2.0     NaN  US News      1           69   \n",
       "2           2           3     3.0     NaN  US News      1           89   \n",
       "3           3           4     4.0     NaN  US News      1           77   \n",
       "4           4           5     5.0     NaN  US News      1           70   \n",
       "\n",
       "   text_count  article_count  title_tokenized_count  ...       NNP       WRB  \\\n",
       "0        2700           2778                      9  ...  0.419287  0.628931   \n",
       "1        1891           1960                      8  ...  0.311526  0.934579   \n",
       "2        3381           3470                     10  ...  0.341297  0.511945   \n",
       "3        2599           2676                      8  ...  0.439560  0.439560   \n",
       "4        2346           2416                      7  ...  0.000000  0.230947   \n",
       "\n",
       "        WDT       PDT        EX  RBS  NNPS   UH  WP$  POS  \n",
       "0  0.209644  0.209644  0.000000  0.0   0.0  0.0  0.0  0.0  \n",
       "1  0.000000  0.000000  0.000000  0.0   0.0  0.0  0.0  0.0  \n",
       "2  0.511945  0.000000  0.170648  0.0   0.0  0.0  0.0  0.0  \n",
       "3  0.879121  0.000000  0.000000  0.0   0.0  0.0  0.0  0.0  \n",
       "4  0.461894  0.230947  0.461894  0.0   0.0  0.0  0.0  0.0  \n",
       "\n",
       "[5 rows x 48 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read CSV file\n",
    "df = pd.read_csv('NLP_df_finalnum(J29).csv')\n",
    "\n",
    "# Check df\n",
    "print(df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5a295799",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['label', 'title_count', 'text_count', 'title_tokenized_count',\n",
       "       'text_tokenized_count', 'US News', 'World News', 'JJ', 'NN', 'VBZ',\n",
       "       'RP', 'VBG', 'VBP', 'DT', 'RB', 'VB', 'CC', 'PRP', 'IN', 'VBD', 'TO',\n",
       "       'PRP$', 'NNS', 'JJS', 'CD', 'JJR', 'RBR', 'VBN', 'MD', 'WP', 'FW',\n",
       "       'NNP', 'WRB', 'WDT', 'PDT', 'EX', 'RBS', 'NNPS', 'UH', 'WP$', 'POS'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Drop columns that will not be used as features\n",
    "df = df.drop(columns=['Unnamed: 0','articlesid','fakeid','trueid','subject','article_count','article_tokenized_count'])\n",
    "\n",
    "# Check df columns\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "490bb45c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label                      int64\n",
       "title_count                int64\n",
       "text_count                 int64\n",
       "title_tokenized_count      int64\n",
       "text_tokenized_count       int64\n",
       "US News                    int64\n",
       "World News                 int64\n",
       "JJ                       float64\n",
       "NN                       float64\n",
       "VBZ                      float64\n",
       "RP                       float64\n",
       "VBG                      float64\n",
       "VBP                      float64\n",
       "DT                       float64\n",
       "RB                       float64\n",
       "VB                       float64\n",
       "CC                       float64\n",
       "PRP                      float64\n",
       "IN                       float64\n",
       "VBD                      float64\n",
       "TO                       float64\n",
       "PRP$                     float64\n",
       "NNS                      float64\n",
       "JJS                      float64\n",
       "CD                       float64\n",
       "JJR                      float64\n",
       "RBR                      float64\n",
       "VBN                      float64\n",
       "MD                       float64\n",
       "WP                       float64\n",
       "FW                       float64\n",
       "NNP                      float64\n",
       "WRB                      float64\n",
       "WDT                      float64\n",
       "PDT                      float64\n",
       "EX                       float64\n",
       "RBS                      float64\n",
       "NNPS                     float64\n",
       "UH                       float64\n",
       "WP$                      float64\n",
       "POS                      float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Show df columns and data types \n",
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "519bb855",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# # Scale data\n",
    "# from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# # Initiate StandardScaler\n",
    "# scaler = StandardScaler()\n",
    "\n",
    "# # Create dataframe without label column\n",
    "# df_nolabel = df.drop(columns= ['label'])\n",
    "\n",
    "# # Fit\n",
    "# scaler.fit(df_nolabel)\n",
    "\n",
    "# # Save the scaler\n",
    "# #pickle.dump(scaler,open('scaler.sav','wb'))\n",
    "\n",
    "# # Transform\n",
    "# df_scaled = pd.DataFrame(scaler.transform(df_nolabel),columns=df_nolabel.columns)\n",
    "\n",
    "# df_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e2f50abb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Add scaled values to dataframe\n",
    "# df.update(df_scaled) \n",
    "# df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "20a0d5a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assign variables (features and target y and X)\n",
    "y = df.label\n",
    "X = df.drop(columns=['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3f9a0c3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import train_test_split module\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split data into training and testing sets \n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=45, test_size=0.20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "62dbbbfe",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# MODEL 1: Naive Bayes/GaussianNB()\n",
    "\n",
    "#Import GaussianNB library\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "# Initiate model\n",
    "gb_model = GaussianNB()\n",
    "\n",
    "# Train model\n",
    "gb_model.fit(X_train, y_train)\n",
    "\n",
    "# Create model predictions\n",
    "y_pred = gb_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "396f74c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "88.97888726596733\n"
     ]
    }
   ],
   "source": [
    "# Validate Model(1): Accuracy Score \n",
    "accuracy = accuracy_score(y_test, gb_model.predict(X_test))*100\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "751dc988",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[3825  443]\n",
      " [ 387 2876]]\n"
     ]
    }
   ],
   "source": [
    "# Validate Model(2): Confusion Matrix\n",
    "print(confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "25734475",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.90      0.90      4268\n",
      "           1       0.87      0.88      0.87      3263\n",
      "\n",
      "    accuracy                           0.89      7531\n",
      "   macro avg       0.89      0.89      0.89      7531\n",
      "weighted avg       0.89      0.89      0.89      7531\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Validate Model(3): Classification Report\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "750ed93c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# # CODE FROM: https://inblog.in/Feature-Importance-in-Naive-Bayes-Classifiers-5qob5d5sFW\n",
    "\n",
    "# # Calculate feature importance in the Naive Bayes/GaussianNB() model.\n",
    "# from sklearn.inspection import permutation_importance\n",
    "\n",
    "# imps = permutation_importance(gb_model, X_test, y_test)\n",
    "# importances = imps.importances_mean\n",
    "# std = imps.importances_std\n",
    "# indices = np.argsort(importances)[::-1]\n",
    "\n",
    "# features = X.columns\n",
    "\n",
    "# # Print the feature ranking\n",
    "# print(\"Feature ranking:\")\n",
    "# for f in range(X_test.shape[1]):\n",
    "#     print(\"%d. %s (%f)\" % (f + 1, features[indices[f]], importances[indices[f]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "af1b4fc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # MODEL 2: SVM\n",
    "\n",
    "# #Import library \n",
    "# from sklearn.svm import SVC\n",
    "\n",
    "# # Initiate model\n",
    "# svm_model = SVC(kernel='linear')\n",
    "\n",
    "# # Train model\n",
    "# svm_model.fit(X_train, y_train)\n",
    "\n",
    "# # Create model predictions\n",
    "# y_pred = svm_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "eb8f43d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Validate Model(1): Accuracy Score \n",
    "# accuracy = accuracy_score(y_test, y_pred)*100\n",
    "# print(accuracy)\n",
    "\n",
    "# # Validate Model(2): Confusion Matrix\n",
    "# print(confusion_matrix(y_test, y_pred))\n",
    "\n",
    "# # Validate Model(3): Classification Report\n",
    "# print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "671db8f5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# # Import permutation_importance library\n",
    "# from sklearn.inspection import permutation_importance\n",
    "\n",
    "# # Calculate feature importance SVM model.\n",
    "# svm_imps = permutation_importance(svm_model, X_test, y_test)\n",
    "# svm_importances = svm_imps.importances_mean\n",
    "# std = svm_imps.importances_std\n",
    "# indices = np.argsort(svm_importances)[::-1]\n",
    "\n",
    "# svm_features = X.columns\n",
    "\n",
    "# # Print the feature ranking\n",
    "# print(\"Feature ranking:\")\n",
    "# for f in range(X_test.shape[1]):\n",
    "#     print(\"%d. %s (%f)\" % (f + 1, svm_features[indices[f]], svm_importances[indices[f]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4a7d37f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save model to disk\n",
    "import pickle\n",
    "filename = 'gb_model.sav'\n",
    "pickle.dump(gb_model, open(filename, 'wb'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf_m1",
   "language": "python",
   "name": "tf_m1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
